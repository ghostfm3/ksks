ニューラルネットワークの層が深くなったものを深層学習
探索と推論→ファジイ理論
フレーム問題→当時の計算機では人工知能は現実問題すべてに対処できない問題が発生した
→現在では解決可能, 時がたてば解決可能な問題はでてくる

deep mind→bengio

教師あり学習→データ量が必要
強化学習→ラベル

機械学習→機械が学習する仕組みをつくる
↳神経細胞のモデルを元にした学習の仕組み→ニューラルネットワーク

神経細胞
入力値→シナプスの入力を反映
Σw_i x_i 掛け足し

θ→閾値
Yがθ以上なら1
θ以下なら0
→ステップ関数で表現[s()みたいな感じ]
s(u)=(1 or 0)
uを入力とした時0以上なら1を返し,未満では0を返す

形式ニューロン
y=s(Σw_i x_i - θ)

→のちにステップ関数からシグモイド関数へ
s(u)=1/1+e^-u
e=2.718281
入力uがながらに1
それ以外は0

入力はベクトルでも表すことができる→ベクトル同士の掛け算になる
閾値のθをbに置き換えると全て足し算で表現できる

学習対象
結合強度w　→閾値bも結合強度に含める
乱数→標準正規分布に従う
入力xで出力yを計算する
教師信号を与えて誤差を算出
出力が正しい→重みは更新無し
以下スライド通り

w[t]
t→t回目の学習ということを表す
シグモイド関数等を用いてyを算出
y[t]→t回目の学習のy

c(z-y(t))
入力(教師)信号z ニューラルネットワークの答えy[t]
ここが0になれば→重みが変化しない→識別が正しく行われた

以下スライド通り

xorは形式ニューロンでは組めないので複雑な問題を解くにはさらに発展した手法が必要になる


