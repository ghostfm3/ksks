分類→予測
学習に用いていない新しいデータを予測

機械学習には2種類のデータを用いる
検証データ
テストデータ

オーバーフィッテング
観測データによく当てはまる→未知のデータには当てはめが悪くなる
過学習
↳モデルに説明変数を追加→残差が減る

過学習が起きているかどうかを分析する方法も存在する

データ分割
ニューラルネットワークは乱数を元に分析を行うため結果にばらつきが生じる

交差確認法
全体をkグループに分け1個を予測能力を評価、残りk-1をモデル作成

予測の精度→分割表
tp:正しく正解を当てた数　fp:間違って正解といった数→第一種の誤り
fn:間違ってネガティブにいった　　tn:正しく間違いを予測した

※資料のfpとfnは逆,後日修正が入るらしい

正解率
全パリエーションの中で正しく予測した部分はどれくらいか
正解と不偏が偏りがある場合は計算が人間の直感とずれた結果となる

適合率
全体のデータの中でどれだけ正しいと予想できるか

再現率
正しいと予測した中でどれだけ正解と予測できるか

トレードオフ
→適合率と再現率は両方評価する必要がある→両方の評価尺度をF値

tp:リンゴがリンゴと判断
fp:リンゴじゃないのにリンゴとはんだん
fn:リンゴなのにリンゴじゃないと判断
ff:間違い

ガン→再現率



NNの問題点
収束性

モデルの選択
→中間層およびユニットの数をいくつかにすればよいのか
情報量規準
正則化+入れ方

中間層の数の決定法(NNの正則化)
モデルがどれくらい妥当か→情報量規準
複数のモデルから必要最小限の説明変数のモデルを選択する方法

AIC
データに対する誤差とパラメータ数を調整する方法

正規分布
c→全体の確率が1になるように調整される部分


尤度
→値が大ほど当てはまりがよい
掛け算は大変なのでlogをとって総和をとる


8回
次元が上がれば予測の精度が下がる
→NNをAIC(情報量規準)で評価する

教師信号0と1に分けると1つの式にまとめることができる

最大化問題なので－をつけない


パラメータに制約を加える正則化
極端なデータにノイズを加える





