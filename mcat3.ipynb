{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mcat3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPMpdgXIVZ+gZKIYb7W3eMq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghostfm3/ksks/blob/master/mcat3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB6l3QPFLVFA"
      },
      "source": [
        "import numpy as np\r\n",
        "import sys\r\n",
        "sys.path.append('..')\r\n",
        "\r\n",
        "def create_context_target(corpus, window_size=1):\r\n",
        "  target = corpus[window_size:-window_size]\r\n",
        "  contexts = []\r\n",
        "\r\n",
        "  for idx in range(window_size, len(corpus)-window_size):\r\n",
        "    cs = []\r\n",
        "    for t in range(-window_size, window_size + 1):\r\n",
        "      if t == 0:\r\n",
        "        continue\r\n",
        "      cs.append(corpus[idx + t])\r\n",
        "    contexts.append(cs)\r\n",
        "  \r\n",
        "  return np.array(contexts), np.array(target)\r\n",
        "\r\n",
        "def preprocess(text):\r\n",
        "  text = text.lower()\r\n",
        "  text = text.replace('.', ' .')\r\n",
        "  words = text.split(' ')\r\n",
        "\r\n",
        "  word_to_id = {}\r\n",
        "  id_to_word = {}\r\n",
        "  for word in words:\r\n",
        "    if word not in word_to_id:\r\n",
        "      new_id = len(word_to_id)\r\n",
        "      word_to_id[word] = new_id\r\n",
        "      id_to_word[new_id] = word \r\n",
        "  \r\n",
        "  corpus = np.array([word_to_id[w] for w in words])\r\n",
        "  return corpus, word_to_id, id_to_word\r\n",
        "\r\n",
        "def convert_one_hot(corpus, vocab_size):\r\n",
        "    '''one-hot表現への変換\r\n",
        "    :param corpus: 単語IDのリスト（1次元もしくは2次元のNumPy配列）\r\n",
        "    :param vocab_size: 語彙数\r\n",
        "    :return: one-hot表現（2次元もしくは3次元のNumPy配列）\r\n",
        "    '''\r\n",
        "    N = corpus.shape[0]\r\n",
        "\r\n",
        "    if corpus.ndim == 1:\r\n",
        "        one_hot = np.zeros((N, vocab_size), dtype=np.int32)\r\n",
        "        for idx, word_id in enumerate(corpus):\r\n",
        "            one_hot[idx, word_id] = 1\r\n",
        "\r\n",
        "    elif corpus.ndim == 2:\r\n",
        "        C = corpus.shape[1]\r\n",
        "        one_hot = np.zeros((N, C, vocab_size), dtype=np.int32)\r\n",
        "        for idx_0, word_ids in enumerate(corpus):\r\n",
        "            for idx_1, word_id in enumerate(word_ids):\r\n",
        "                one_hot[idx_0, idx_1, word_id] = 1\r\n",
        "\r\n",
        "    return one_hot\r\n",
        "\r\n",
        "text = 'You say goodbye and I say hello.'\r\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\r\n",
        "\r\n",
        "contexts, target = create_context_target(corpus, window_size=1)\r\n",
        "\r\n",
        "vocab_size = len(word_to_id)\r\n",
        "target = convert_one_hot\r\n",
        "contexts = convert_one_hot(contexts, vocab_size)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    }
  ]
}